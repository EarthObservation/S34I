{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128739c7-265a-46da-bb8e-b9b9b3201e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the file paths for your DataFrames:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path to Contacts_Measured CSV:  \n",
      "Path to Contacts CSV:  \n",
      "Path to Measured CSV:  \n",
      "Path to Random_Points CSV:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Where would you like to save the performance metrics?\n",
      "1. Use default temporary location\n",
      "2. Specify a custom path\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def calculate_performance_metrics(Contacts_Measured, Contacts, Measured, Random_Points, input_files):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics based on input DataFrames\n",
    "    \n",
    "    Parameters:\n",
    "    - Contacts_Measured: DataFrame with contact and measurement information\n",
    "    - Contacts: DataFrame with ground truth contacts\n",
    "    - Measured: DataFrame with extracted measurements\n",
    "    - Random_Points: DataFrame with random points\n",
    "    - input_files: Dictionary of input file paths\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    # Calculate True Positives (TP)\n",
    "    Contacts_Measured_Az_Match = Contacts_Measured[Contacts_Measured['Az_Match'] == 1]\n",
    "    result_Contacts_Measured = Contacts_Measured_Az_Match.drop_duplicates(subset=['IN_FID'])\n",
    "    arr_Contacts_Measured = result_Contacts_Measured[['IN_FID']].to_numpy()\n",
    "    TP = len(arr_Contacts_Measured)\n",
    "\n",
    "    # Calculate part of False Negatives (FN_1)\n",
    "    Contacts_Measured_Az_Match_1 = Contacts_Measured[Contacts_Measured['Az_Match'] == 0]\n",
    "    result_Contacts_Measured_1 = Contacts_Measured_Az_Match_1.drop_duplicates(subset=['IN_FID'])\n",
    "    arr_Contacts_Measured_1 = result_Contacts_Measured_1[['IN_FID']].to_numpy()\n",
    "    \n",
    "    # Process Contacts and Measured DataFrames\n",
    "    result_Contacts = Contacts.drop_duplicates(subset=['IN_FID'])\n",
    "    arr_Contacts = result_Contacts[['IN_FID']].to_numpy()\n",
    "    \n",
    "    result_Measured = Measured.drop_duplicates(subset=['IN_FID'])\n",
    "    arr_Measured = result_Measured[['IN_FID']].to_numpy()\n",
    "\n",
    "    # Calculate intersections\n",
    "    intersect_contacts_measured = np.intersect1d(arr_Contacts, arr_Measured)\n",
    "    \n",
    "    # Calculate False Negatives\n",
    "    FN_2 = len(arr_Measured) - len(intersect_contacts_measured)\n",
    "    \n",
    "    # Calculate False Positives\n",
    "    dif_contacts_measured = np.setdiff1d(arr_Contacts, arr_Measured)\n",
    "    dif_measured_contacts = np.setdiff1d(arr_Measured, arr_Contacts)\n",
    "    \n",
    "    # Additional calculations for FN_1\n",
    "    intersect = np.intersect1d(arr_Contacts_Measured, arr_Contacts_Measured_1)\n",
    "    FN_1_arr = np.setdiff1d(arr_Contacts_Measured_1, intersect)\n",
    "    FN_1 = len(arr_Contacts_Measured_1) - len(intersect)\n",
    "\n",
    "    # Calculate True Negatives (TN)\n",
    "    Random_Points_TN = Random_Points[Random_Points['NEAR_ANGLE'] == 0]\n",
    "    random_points_arr = Random_Points_TN[['OBJECTID']].to_numpy()\n",
    "    \n",
    "    TN_1 = np.intersect1d(random_points_arr, arr_Measured)\n",
    "    TN_2 = np.intersect1d(random_points_arr, arr_Contacts)\n",
    "    TN_1_1 = np.intersect1d(TN_1, TN_2)\n",
    "    \n",
    "    TN = len(random_points_arr) - (len(TN_1) + len(TN_2)) + len(TN_1_1)\n",
    "\n",
    "    # Finalize False Negatives and False Positives\n",
    "    FN = len(dif_contacts_measured) + len(FN_1_arr)\n",
    "    FP = len(dif_measured_contacts)\n",
    "\n",
    "    # Calculate Performance Metrics\n",
    "    total_samples = TP + TN + FP + FN\n",
    "    \n",
    "    # Combine metrics with input file information\n",
    "    metrics = {\n",
    "        # Input file identifiers\n",
    "        'Contacts_Measured_File': os.path.basename(input_files['contacts_measured']),\n",
    "        'Contacts_File': os.path.basename(input_files['contacts']),\n",
    "        'Measured_File': os.path.basename(input_files['measured']),\n",
    "        'Random_Points_File': os.path.basename(input_files['random_points']),\n",
    "        \n",
    "        # Performance metrics\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'Total_Samples': total_samples,\n",
    "        'Accuracy': (TP + TN) / total_samples,\n",
    "        'Precision': TP / (TP + FP) if (TP + FP) > 0 else 0,\n",
    "        'Recall': TP / (TP + FN) if (TP + FN) > 0 else 0,\n",
    "        'F1_Score': TP / (TP + ((FN + FP) / 2)) if (TP + ((FN + FP) / 2)) > 0 else 0,\n",
    "        'FPR': FP / (FP + TN) if (FP + TN) > 0 else 0,\n",
    "        'Specificity': TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def save_metrics_to_csv(metrics, output_file='performance_metrics.csv'):\n",
    "    \"\"\"\n",
    "    Save performance metrics to a CSV file with robust error handling\n",
    "    \n",
    "    Parameters:\n",
    "    - metrics: Dictionary of performance metrics\n",
    "    - output_file: Path to the output CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to save to the specified location\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        \n",
    "        # Check if file exists\n",
    "        file_exists = os.path.isfile(output_file)\n",
    "        \n",
    "        # Convert metrics to DataFrame\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        \n",
    "        # Append to existing file or create new\n",
    "        if file_exists:\n",
    "            metrics_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "            print(f\"Metrics appended to {output_file}\")\n",
    "        else:\n",
    "            metrics_df.to_csv(output_file, index=False)\n",
    "            print(f\"Metrics saved to new file {output_file}\")\n",
    "    \n",
    "    except PermissionError:\n",
    "        # If permission is denied, use a temporary file\n",
    "        temp_file = os.path.join(tempfile.gettempdir(), 'performance_metrics.csv')\n",
    "        \n",
    "        # Check if file exists\n",
    "        file_exists = os.path.isfile(temp_file)\n",
    "        \n",
    "        # Convert metrics to DataFrame\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        \n",
    "        # Append to existing file or create new\n",
    "        if file_exists:\n",
    "            metrics_df.to_csv(temp_file, mode='a', header=False, index=False)\n",
    "            print(f\"Permission denied. Metrics appended to temporary file: {temp_file}\")\n",
    "        else:\n",
    "            metrics_df.to_csv(temp_file, index=False)\n",
    "            print(f\"Permission denied. Metrics saved to temporary file: {temp_file}\")\n",
    "        \n",
    "        # Suggest alternative save location\n",
    "        print(\"Unable to save to specified location due to permission issues.\")\n",
    "        print(f\"Temporary file saved at: {temp_file}\")\n",
    "        print(\"Please copy this file to your desired location manually.\")\n",
    "\n",
    "# Example usage (you would replace these with your actual DataFrames)\n",
    "def main():\n",
    "    # Manually input or load your DataFrames\n",
    "    print(\"Please input the file paths for your DataFrames:\")\n",
    "    contacts_measured_path = input(\"Path to Contacts_Measured CSV: \")\n",
    "    contacts_path = input(\"Path to Contacts CSV: \")\n",
    "    measured_path = input(\"Path to Measured CSV: \")\n",
    "    random_points_path = input(\"Path to Random_Points CSV: \")\n",
    "    \n",
    "    # Create input files dictionary\n",
    "    input_files = {\n",
    "        'contacts_measured': contacts_measured_path,\n",
    "        'contacts': contacts_path,\n",
    "        'measured': measured_path,\n",
    "        'random_points': random_points_path\n",
    "    }\n",
    "    \n",
    "    # Prompt for output file path with a default\n",
    "    print(\"\\nWhere would you like to save the performance metrics?\")\n",
    "    print(\"1. Use default temporary location\")\n",
    "    print(\"2. Specify a custom path\")\n",
    "    choice = input(\"Enter 1 or 2: \").strip()\n",
    "    \n",
    "    if choice == '2':\n",
    "        output_file = input(\"Enter full path to save performance metrics CSV (including filename): \")\n",
    "    else:\n",
    "        # Use a default name in the temporary directory\n",
    "        output_file = os.path.join(tempfile.gettempdir(), 'performance_metrics.csv')\n",
    "    \n",
    "    # Load DataFrames\n",
    "    Contacts_Measured = pd.read_csv(contacts_measured_path)\n",
    "    Contacts = pd.read_csv(contacts_path)\n",
    "    Measured = pd.read_csv(measured_path)\n",
    "    Random_Points = pd.read_csv(random_points_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_performance_metrics(Contacts_Measured, Contacts, Measured, Random_Points, input_files)\n",
    "    \n",
    "    # Print metrics to console\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    save_metrics_to_csv(metrics, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0afc46-396f-4edf-b337-851ec305efa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
